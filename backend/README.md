# Backend - 3-Agent CrewAI Pipeline

AI-powered nurse scheduling backend using CrewAI with 3 specialized agents and Timefold constraint optimization.

## ğŸ¤– Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FastAPI Server (Port 5000)                   â”‚
â”‚  POST /api/schedule/{rota_id} â†’ Runs 3-Agent Pipeline               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AGENT 1   â”‚â”€â”€â”€â–¶â”‚   AGENT 2   â”‚â”€â”€â”€â–¶â”‚   AGENT 3   â”‚
â”‚ Data Fetch  â”‚    â”‚ Code Gen    â”‚    â”‚  Executor   â”‚
â”‚  Supabase   â”‚    â”‚  Timefold   â”‚    â”‚   Solver    â”‚
â”‚    â†’ JSON   â”‚    â”‚  â†’ Python   â”‚    â”‚  â†’ Result   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crew.py              # 3-Agent pipeline (main)
â”‚   â”œâ”€â”€ api.py               # FastAPI endpoints
â”‚   â”œâ”€â”€ main.py              # CLI entry point
â”‚   â”œâ”€â”€ config.py            # Environment config
â”‚   â”œâ”€â”€ supabase_client.py   # Supabase singleton
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ data_fetcher.py  # Agent 1 helper
â”‚   â”‚   â””â”€â”€ timefold_transformer.py  # Agent 2 helper
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”‚   â””â”€â”€ tools/
â”‚       â””â”€â”€ supabase_tool.py # FetchRotaDataTool
â”œâ”€â”€ generated/               # Agent 2 output (gitignored)
â”‚   â”œâ”€â”€ domain.py
â”‚   â”œâ”€â”€ constraints.py
â”‚   â”œâ”€â”€ solver.py
â”‚   â””â”€â”€ input_data.json
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ tables_creation.sql
â”‚   â””â”€â”€ sample_data.sql
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
```

Edit `.env`:
```env
# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-key

# Vertex AI
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_GENAI_USE_VERTEXAI=True

# Langfuse (optional)
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_BASE_URL=https://cloud.langfuse.com
```

### 3. Authenticate with Google Cloud

```bash
gcloud auth application-default login
```

### 4. Run the API Server

```bash
python -m uvicorn src.api:app --host 0.0.0.0 --port 5000
```

API available at: http://localhost:5000

---

## ğŸ”Œ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API info |
| GET | `/api/health` | Health check |
| POST | `/api/schedule/{rota_id}` | Generate schedule |

### Example Request

```bash
curl -X POST http://localhost:5000/api/schedule/22222222-2222-2222-2222-222222222222
```

### Example Response

```json
{
  "status": "success",
  "score": "0hard/-5soft",
  "schedule": [
    {"date": "2026-02-01", "employeeId": "s1", "employeeName": "Fatima Hassan", "shiftCode": "M"},
    {"date": "2026-02-01", "employeeId": "s2", "employeeName": "Ahmed Ali", "shiftCode": "E"}
  ],
  "summary": {
    "totalShifts": 84,
    "assignedShifts": 84,
    "unassignedShifts": 0,
    "employeeHours": {
      "Fatima Hassan": 144,
      "Ahmed Ali": 160,
      "Huda Mohammed": 120,
      "Omar Khalid": 160
    }
  }
}
```

---

## ğŸ–¥ï¸ CLI Usage

Run the scheduling pipeline from command line:

```bash
python -m src.main --rota-id "22222222-2222-2222-2222-222222222222"
```

With output file:

```bash
python -m src.main --rota-id "22222222-2222-2222-2222-222222222222" --output schedule.json
```

---

## ğŸ¤– Agent Details

### Agent 1: Data Interpreter

**Goal**: Fetch and analyze scheduling data from Supabase

**Expertise**:
- Shift code interpretation (M/E/N = work, AL/SL = paid absence, DO = day off)
- Hours calculation: `targetHours = contractedHours + owingHours - paidAbsenceHours`
- Implicit requirement detection (mentorship from comments)
- Rest period rules (10h between shifts, max 3 consecutive nights)

**Output**: Timefold JSON specification

---

### Agent 2: Code Generator

**Goal**: Generate Timefold Python code from JSON spec

**Files Generated**:
1. `domain.py` - Employee, Shift, ShiftSchedule classes
2. `constraints.py` - Hard/soft constraints
3. `solver.py` - Solver configuration
4. `input_data.json` - Input for solver

**Tools**: FileReadTool, FileWriterTool

---

### Agent 3: Executor

**Goal**: Execute solver and format output

**Output**: JSON for frontend with schedule array and summary

---

## ğŸ“¦ Dependencies

```
crewai>=0.86.0
crewai-tools>=0.17.0
google-cloud-aiplatform>=1.38.0
supabase>=2.0.0
fastapi>=0.109.0
uvicorn>=0.27.0
timefold>=1.0.0
langfuse>=2.0.0
openinference-instrumentation-crewai>=0.1.0
python-dotenv>=1.0.0
litellm>=1.1.0
pydantic>=2.5.0
```

---

## ğŸ” Debugging with Langfuse

View full agent execution traces at [cloud.langfuse.com](https://cloud.langfuse.com):

- Every agent step
- LLM calls and responses
- Tool invocations
- Token usage

---

## ğŸ“„ License

MIT
